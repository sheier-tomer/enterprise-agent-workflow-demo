# Enterprise Agentic Workflow Engine (Finance Demo)

> **âš ï¸ IMPORTANT DISCLAIMER âš ï¸**
> 
> **This is a DEMONSTRATION PROJECT for educational and portfolio purposes only.**
> 
> - âœ… All data is **SYNTHETIC** and generated by the Faker library
> - âœ… All examples are **FICTIONAL** and for demonstration purposes
> - âœ… All policy documents are **MOCK** representations
> - âŒ **NO real customer data** is used or should be used
> - âŒ **NO real financial institutions** are referenced
> - âŒ **NOT intended for production use** or with actual customer information
> - âŒ **NOT a real banking or financial system**
> 
> This project demonstrates backend engineering patterns and should be treated as a learning resource only.

---

## What This Project Demonstrates

This is a **production-quality demo** showcasing how to build an enterprise-grade agentic workflow orchestration backend using modern Python tools and architectural patterns:

### Core Technologies

- **FastAPI**: Async REST API with Pydantic validation
- **LangGraph**: State machine orchestration with conditional routing
- **PostgreSQL + pgvector**: Vector similarity search for RAG
- **SQLAlchemy 2.0**: Async ORM with relationship management
- **Alembic**: Database migrations
- **Docker**: Containerized deployment with docker-compose

### Key Features

- **ğŸ¤– Agentic Workflows**: Multi-step LangGraph state machine with conditional branching
- **ğŸ“š RAG (Retrieval-Augmented Generation)**: Policy document retrieval using pgvector similarity search
- **ğŸ›¡ï¸ Guardrails**: Tool allowlisting, schema validation, content filtering, rate limiting
- **ğŸ“‹ Audit Logging**: Append-only immutable audit trail for every workflow step
- **âœ… Strict Validation**: Pydantic models for all tool inputs/outputs
- **ğŸ”„ Dual Mode**: Mock mode (no API key) or real LLM mode (OpenAI)
- **ğŸ§ª Testing**: Pytest with async support and fixtures

---

## Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Client (REST API)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FastAPI API Layer                        â”‚
â”‚  â€¢ POST /tasks/run                                          â”‚
â”‚  â€¢ GET /tasks/{id}                                          â”‚
â”‚  â€¢ GET /tasks/{id}/audit                                    â”‚
â”‚  â€¢ GET /health                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Guardrails Enforcement Layer                   â”‚
â”‚  â€¢ Tool allowlist validation                                â”‚
â”‚  â€¢ Pydantic schema validation                               â”‚
â”‚  â€¢ Content filtering (PII, institutions)                    â”‚
â”‚  â€¢ Rate limiting                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                LangGraph State Machine                      â”‚
â”‚                                                             â”‚
â”‚  START â†’ Ingest â†’ Detect â†’ Retrieve â†’ Draft â†’ Evaluate     â”‚
â”‚                                           â”‚                 â”‚
â”‚                                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚                                 â–¼                   â–¼       â”‚
â”‚                            Escalate             Finalize    â”‚
â”‚                                 â”‚                   â”‚       â”‚
â”‚                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                           â–¼                 â”‚
â”‚                                         END                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Tools      â”‚  â”‚   RAG        â”‚  â”‚   Audit      â”‚
â”‚   Registry   â”‚  â”‚   System     â”‚  â”‚   Logger     â”‚
â”‚              â”‚  â”‚              â”‚  â”‚              â”‚
â”‚ â€¢ Analyzer   â”‚  â”‚ â€¢ Embeddings â”‚  â”‚ â€¢ Events     â”‚
â”‚ â€¢ Detector   â”‚  â”‚ â€¢ Retriever  â”‚  â”‚ â€¢ Duration   â”‚
â”‚ â€¢ Drafter    â”‚  â”‚ â€¢ Indexer    â”‚  â”‚ â€¢ Tool calls â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚                 â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   PostgreSQL         â”‚
              â”‚   + pgvector         â”‚
              â”‚                      â”‚
              â”‚ â€¢ Customers          â”‚
              â”‚ â€¢ Transactions       â”‚
              â”‚ â€¢ Policy Docs        â”‚
              â”‚ â€¢ Workflow Runs      â”‚
              â”‚ â€¢ Audit Events       â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Workflow State Machine

The LangGraph workflow executes these steps:

1. **Ingest Transactions** â†’ Analyze customer transaction history
2. **Detect Anomalies** â†’ Identify suspicious patterns using heuristics
3. **Retrieve Policies** â†’ RAG-based policy document search
4. **Draft Explanation** â†’ Generate natural language analysis
5. **Evaluate Confidence** â†’ Decision node for routing
6. **Escalate** (if confidence < 0.7) â†’ Flag for human review
7. **Finalize** â†’ Assemble final result

Every step is logged to an immutable audit trail with timestamps, inputs, outputs, and duration.

---

## Quick Start

### Prerequisites

- Docker and Docker Compose
- Git

### Option 1: Run with Docker (Recommended)

```bash
# Clone the repository
git clone <your-repo-url>
cd EnterpriseAIWorkflow

# Start the services
docker-compose up --build

# Wait for startup (database seeding + indexing takes ~30 seconds)
# Application will be available at http://localhost:8000
```

### Option 2: Local Development

```bash
# Install dependencies
python3.11 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# Set up environment
cp .env.example .env
# Edit .env to configure database URL

# Start PostgreSQL with pgvector
docker-compose up db

# Run migrations
alembic upgrade head

# Start the application
python -m app.main

# Or use uvicorn directly
uvicorn app.main:app --reload
```

### Verify Installation

```bash
# Health check
curl http://localhost:8000/api/v1/health

# API documentation
open http://localhost:8000/docs
```

---

## API Usage Examples

### 1. Run a Workflow

```bash
# Get a customer ID first (after seeding)
curl http://localhost:8000/api/v1/health

# Run workflow for a customer
curl -X POST http://localhost:8000/api/v1/tasks/run \
  -H "Content-Type: application/json" \
  -d '{
    "customer_id": "YOUR_CUSTOMER_UUID_HERE",
    "analysis_window_days": 30,
    "anomaly_threshold": 0.8
  }'

# Response:
# {
#   "task_id": "workflow-run-uuid",
#   "customer_id": "customer-uuid",
#   "status": "running",
#   "created_at": "2026-02-12T..."
# }
```

### 2. Get Workflow Status and Results

```bash
curl http://localhost:8000/api/v1/tasks/{task_id}

# Response:
# {
#   "task_id": "...",
#   "customer_id": "...",
#   "status": "completed",
#   "result": {
#     "anomalies_detected": 3,
#     "confidence_score": 0.85,
#     "is_escalated": false,
#     "explanation": "Analysis of 47 transactions...",
#     "matched_policies": ["Policy-001", "Policy-004"],
#     "recommended_actions": ["flag_for_review", "notify_customer"]
#   },
#   "audit_event_count": 7,
#   "duration_ms": 1240
# }
```

### 3. Get Audit Trail

```bash
curl http://localhost:8000/api/v1/tasks/{task_id}/audit

# Response:
# {
#   "task_id": "...",
#   "total_events": 7,
#   "events": [
#     {
#       "id": "event-uuid",
#       "node_name": "ingest_transactions",
#       "tool_name": "transaction_analyzer",
#       "duration_ms": 145,
#       "timestamp": "2026-02-12T..."
#     },
#     ...
#   ]
# }
```

### 4. Interactive Documentation

Visit `http://localhost:8000/docs` for Swagger UI with interactive API testing.

---

## Project Structure

```
EnterpriseAIWorkflow/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # FastAPI app + lifespan
â”‚   â”œâ”€â”€ config.py                  # Pydantic Settings
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ router.py              # REST endpoints
â”‚   â”‚   â””â”€â”€ schemas.py             # Request/response models
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ state.py               # WorkflowState TypedDict
â”‚   â”‚   â”œâ”€â”€ nodes.py               # Node functions
â”‚   â”‚   â””â”€â”€ graph.py               # LangGraph compilation
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ registry.py            # Tool registry + guardrails
â”‚   â”‚   â”œâ”€â”€ transaction_analyzer.py
â”‚   â”‚   â”œâ”€â”€ anomaly_detector.py
â”‚   â”‚   â””â”€â”€ explanation_drafter.py
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ embeddings.py          # Embedding providers
â”‚   â”‚   â”œâ”€â”€ retriever.py           # pgvector search
â”‚   â”‚   â””â”€â”€ indexer.py             # Document indexing
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ base.py                # SQLAlchemy base
â”‚   â”‚   â”œâ”€â”€ models.py              # 5 tables
â”‚   â”‚   â””â”€â”€ session.py             # Async session
â”‚   â”œâ”€â”€ audit/
â”‚   â”‚   â””â”€â”€ logger.py              # Audit event logger
â”‚   â”œâ”€â”€ guardrails/
â”‚   â”‚   â””â”€â”€ enforcement.py         # Guardrail enforcement
â”‚   â”œâ”€â”€ policies/
â”‚   â”‚   â””â”€â”€ loader.py              # Policy utilities
â”‚   â””â”€â”€ demo_data/
â”‚       â”œâ”€â”€ customers.py           # Faker customers
â”‚       â”œâ”€â”€ transactions.py        # Synthetic transactions
â”‚       â”œâ”€â”€ policies.py            # Mock policies
â”‚       â””â”€â”€ seed.py                # Seeder orchestrator
â”œâ”€â”€ alembic/                       # Database migrations
â”œâ”€â”€ tests/                         # Pytest test suite
â”œâ”€â”€ docker-compose.yml             # Docker services
â”œâ”€â”€ Dockerfile                     # Multi-stage build
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ .env.example                   # Environment template
â””â”€â”€ README.md                      # This file
```

---

## Database Schema

### Tables

- **customers**: Synthetic customer records (UUID, name, email, account_type)
- **transactions**: Transaction history with anomaly labels (UUID, amount, merchant, timestamp)
- **policy_documents**: Mock policies with vector embeddings (UUID, title, content, embedding)
- **workflow_runs**: Workflow execution records (UUID, status, input_params, result)
- **audit_events**: Immutable audit trail (UUID, node_name, tool_name, duration, timestamp)

### Indexes

- Primary keys on all IDs (UUIDs)
- Foreign keys with cascading deletes
- B-tree indexes on timestamps, status fields
- **HNSW vector index** on policy embeddings for fast similarity search

---

## Design Decisions

### Why LangGraph?

LangGraph provides:
- **State management**: Shared state across nodes
- **Conditional routing**: Confidence-based escalation
- **Composability**: Easy to add/remove nodes
- **Observability**: Built-in execution tracking

### Why pgvector?

pgvector offers:
- **PostgreSQL integration**: Single database for all data
- **Performance**: HNSW indexing for fast similarity search
- **Simplicity**: No separate vector database to manage
- **Reliability**: PostgreSQL's ACID guarantees

### Why Dual Mode (Mock + Real)?

- **Accessibility**: Anyone can run the demo without API keys
- **Cost**: No OpenAI charges for basic exploration
- **Testing**: Deterministic outputs in tests
- **Flexibility**: Easy to switch modes via environment variables

### Why Strict Guardrails?

Demonstrates:
- **Security**: Prevent tool injection attacks
- **Compliance**: Content filtering for regulated industries
- **Quality**: Schema validation ensures data integrity
- **Safety**: Rate limiting prevents runaway workflows

### Why Append-Only Audit Logs?

- **Immutability**: No tampering with historical records
- **Compliance**: Regulatory requirements for financial systems
- **Debugging**: Complete execution trace for troubleshooting
- **Accountability**: Who did what, when, and why

---

## Configuration

All configuration is via environment variables (see `.env.example`):

### Database

```bash
DATABASE_URL=postgresql+asyncpg://user:pass@host:5432/db
DATABASE_ECHO=false
```

### LLM Mode

```bash
USE_MOCK_LLM=true                # true = mock, false = real
OPENAI_API_KEY=                  # Required for real mode
OPENAI_MODEL=gpt-4o-mini
```

### Embeddings

```bash
EMBEDDING_PROVIDER=sentence-transformers  # Options: openai, sentence-transformers, mock
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384
```

### Guardrails

```bash
CONFIDENCE_THRESHOLD=0.7         # Below this = escalate
MAX_TOOL_CALLS_PER_WORKFLOW=20
```

### Seeding

```bash
SEED_ON_STARTUP=true
SEED_CUSTOMERS_COUNT=50
SEED_TRANSACTIONS_COUNT=500
SEED_POLICIES_COUNT=10
```

---

## Testing

### Run Tests

```bash
# Install test dependencies (included in requirements.txt)
pip install pytest pytest-asyncio httpx

# Run all tests
pytest

# Run with coverage
pytest --cov=app --cov-report=html

# Run specific test file
pytest tests/test_workflow.py

# Run with verbose output
pytest -v
```

### Test Coverage

The test suite includes:
- **Unit tests**: Individual tool validation
- **Integration tests**: API endpoint testing
- **Guardrail tests**: Safety and validation checks
- **Pydantic tests**: Schema validation

Note: Full end-to-end tests require PostgreSQL with pgvector, which is not available in SQLite test fixtures.

---

## Development

### Code Quality

```bash
# Format code
black app/ tests/

# Lint code
ruff check app/ tests/

# Type checking (if mypy is added)
mypy app/
```

### Database Migrations

```bash
# Create a new migration
alembic revision --autogenerate -m "description"

# Apply migrations
alembic upgrade head

# Rollback one migration
alembic downgrade -1
```

### Debugging

Set `LOG_LEVEL=DEBUG` in `.env` for detailed logging:

```bash
LOG_LEVEL=DEBUG
DATABASE_ECHO=true
```

---

## Performance Considerations

### Optimizations

- **Async all the way**: FastAPI, SQLAlchemy, LangGraph nodes
- **Connection pooling**: Configured in `db/session.py`
- **HNSW indexing**: Fast approximate nearest neighbor search
- **Batch processing**: Embeddings generated in batches
- **Result caching**: WorkflowRun stores result for repeat queries

### Scaling

For production scale:
- Use Celery/Redis for async workflow execution
- Implement caching layer (Redis)
- Add read replicas for database
- Deploy multiple app containers behind load balancer
- Use managed PostgreSQL (RDS, CloudSQL, etc.)

---

## Security Notes

### For Demo Purposes Only

- No authentication/authorization implemented
- CORS is wide open (`allow_origins=["*"]`)
- Database credentials in plain text
- No rate limiting at API level
- No input sanitization beyond Pydantic validation

### For Production

Would need:
- OAuth2/JWT authentication
- Role-based access control (RBAC)
- API key management
- Request rate limiting (e.g., slowapi)
- Input sanitization and XSS prevention
- SQL injection protection (use parameterized queries)
- Secrets management (Vault, AWS Secrets Manager)
- Network security (VPC, security groups)
- Encryption at rest and in transit

---

## Troubleshooting

### Database connection fails

```bash
# Check PostgreSQL is running
docker-compose ps

# Check logs
docker-compose logs db

# Restart services
docker-compose restart
```

### Embeddings fail

```bash
# Check embedding provider in .env
EMBEDDING_PROVIDER=sentence-transformers  # or mock

# For sentence-transformers, first run downloads model (~80MB)
# Check app logs for download progress
```

### Workflow execution hangs

```bash
# Check audit logs for the workflow
curl http://localhost:8000/api/v1/tasks/{task_id}/audit

# Check app logs
docker-compose logs app

# Increase LOG_LEVEL for more detail
LOG_LEVEL=DEBUG
```

---

## Future Enhancements

Potential additions for learning purposes:

- **Human-in-the-loop**: Pause workflow for human input
- **Streaming**: Stream LLM responses via WebSocket
- **Multi-tenancy**: Separate data by organization
- **Advanced RAG**: Hybrid search (vector + keyword)
- **Workflow visualization**: Mermaid diagram generation
- **Metrics**: Prometheus metrics + Grafana dashboards
- **Tracing**: OpenTelemetry distributed tracing
- **CI/CD**: GitHub Actions for testing + deployment

---

## License

This is a demonstration project. Use at your own discretion. Not licensed for commercial use.

---

## Acknowledgments

This project demonstrates patterns from:
- **LangChain/LangGraph**: Agentic workflow orchestration
- **FastAPI**: Modern async Python web framework
- **pgvector**: PostgreSQL vector similarity search
- **Pydantic**: Data validation and settings management

Built as a portfolio project to showcase backend engineering skills.

---

## Contact

For questions about this demo project, please open an issue on GitHub.

**Remember: This is a demo project with synthetic data only. Do not use with real customer information.**
